### Global configurations
# Base URL for Mistral AI endpoints
quarkus.langchain4j.mistralai.base-url=https://mixtral-8x22b-instruct-v01.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1
# Activate or not the log during the request
quarkus.langchain4j.mistralai.log-requests=true
# Activate or not the log during the response
quarkus.langchain4j.mistralai.log-responses=true
# Delay before raising a timeout exception
quarkus.langchain4j.mistralai.timeout=60s
# Your OVH AI enpoint key here
quarkus.langchain4j.mistralai.api-key=foobar

# Activate or not the Mistral AI embedding model
quarkus.langchain4j.mistralai.embedding-model.enabled=false

### Chat model configurations
# Activate or not the Mistral AI chat model
quarkus.langchain4j.mistralai.chat-model.enabled=true
# Chat model name used
quarkus.langchain4j.mistralai.chat-model.model-name=Mixtral-8x22B-Instruct-v0.1
# Number of tokens to use
quarkus.langchain4j.mistralai.chat-model.max-tokens=1024