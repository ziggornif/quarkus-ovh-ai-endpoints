### OVH AI API Key
ovh.ai.api-key=${OVH_API_TOKEN}
### Mistral AI
quarkus.langchain4j.mistralai.base-url=https://mixtral-8x22b-instruct-v01.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1
# Activate or not the log during the request
quarkus.langchain4j.mistralai.log-requests=true
# Activate or not the log during the response
quarkus.langchain4j.mistralai.log-responses=true
# Delay before raising a timeout exception
quarkus.langchain4j.mistralai.timeout=60s
# Your OVH AI enpoint key here
quarkus.langchain4j.mistralai.api-key=${ovh.ai.api-key}
# Activate or not the Mistral AI embedding model
quarkus.langchain4j.mistralai.embedding-model.enabled=false
### Chat model configurations
# Activate or not the Mistral AI chat model
quarkus.langchain4j.mistralai.chat-model.enabled=true
# Chat model name used
quarkus.langchain4j.mistralai.chat-model.model-name=Mixtral-8x22B-Instruct-v0.1
# Number of tokens to use
quarkus.langchain4j.mistralai.chat-model.max-tokens=1024
### Stable diffusion
# endpoint
quarkus.rest-client."xyz.ziggornif.chatbot.service.StableDiffusionService".url=https://stable-diffusion-xl.endpoints.kepler.ai.cloud.ovh.net/api
# bearer
stable-diffusion-client.bearer=Bearer ${ovh.ai.api-key}
### OCR Llava
# endpoint
#quarkus.rest-client."xyz.ziggornif.chatbot.service.OCRService".url=https://llava-next-mistral-7b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1/chat
quarkus.rest-client.ocr-service.url=https://llava-next-mistral-7b.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1/chat
# bearer
llava-client.bearer=Bearer ${ovh.ai.api-key}
#quarkus.rest-client.logging.scope=request-response
#quarkus.log.category."org.jboss.resteasy.reactive.client".level=DEBUG
#quarkus.rest-client.logging.body-limit=100000
quarkus.rest-client.read-timeout=60000